# Introduction
In this report, I will show the methods used to predict the S&P 500 index. Developing methods to predict how much percent change the closing price of the S&P 500 index changes on a day to day basis will help me get a glimpse of what my future may hold. As well as give me a little bit of experience and teach me different aspects of predicting the stock market. The coding language that was used was Python3, along with Numpy and Pandas to manipulate csv files. TensorFlow was also utilized to create the neural network model to carry out the predictions. All the data was retrieved from yahoo finance. 
# Methods
A long short-term memory (LSTM) neural network was used to predict how much percent change the close price of the S&P 500 index changes on a day to day basis. A LSTM neural network is a type of recurrent neural network (RNN). RNNs are used when maintaining information in memory over time. It can be difficult to train standard RNNs that have long term dependencies like the stock market because predicting the stock market requires looking at trends over long periods of time. Standard RNNs would not work well. However, as LSTMs have a memory cell within them that maintains information for long periods of time, LSTMs can remember the trends of the stock market.\
\
In this project,  the data used is from 1/5/88 to 10/17/20 of the S&P 500 and the Dax, a German index. The Dax closes right before the US markets open and it includes companies like Adidas, Volkswagen, etc. The Dax should provide useful information about how the S&P 500 performs that day because there are similar companies in the S&P 500 like Nike and Ford. Other countries' indexes are good predictors for other indexes throughout the world. A recent example of this is in mid February 2020 through March 2020. This time period was when Covid first started becoming a pandemic. Both the Dax and S&P 500 indexes, as well as many other indexes like the UK FTSE 100 index, crashed during this time period. Additionally, the 5 day average closing price for the S&P 500 and Dax was calculated for each day because the model would be able to tell if the price for that day seemed high or low compared to the previous 5 days.\
Data from 1/5/88 to 10/5/12 was used for training which is 75% of the data, and the testing data is from 10/8/12 to 10/14/20 which is 25% of the data. The testing data tests a little over 8 years which is long enough to see if the model performs well over a long period of time because if the testing data tested only 1 year. The model may perform really well that year, but if the testing data had more than 1 year. We may see that the model only performs well that one year and terribly all the other years. Having more testing data gives better results to the models overall performance.\
\
	I started this project with the intention of predicting the closing price of the S&P 500. However,  the prices of the S&P 500 kept increasing, the training data did not have any reference to current day dollars and the model doesn’t take inflation into account. Because of this, the model was always predicting closing prices lower than the actual closing price. The model was reworked to predict how much the closing price changed every day in percentage because there is usually less than a 5% change in the price each day, and inflation wouldn’t affect the percent change. Also, the model now would be able to train on most of the percentages it should encounter in the test data.\
\
Three models were developed using the adam optimizer and mean squared error to calculate loss. With no definitive ‘best’ starting point for the number of neurons and hidden layers, I decided multiples of 25 would be a good start for the number of neurons with 3 hidden layers because. I’ve used multiple of 25s in past neural network projects, with success in past projects. The input layers had 60 neurons, the first and second hidden layers had 50 neurons, the third hidden layer had 25 densely connected neurons, and the output layer just had one neuron.\
\
The second model also had 3 hidden layers, but this model had multiples of 32 instead of 25 and added a dropout because traditionally in computer science you pick powers of 2. The input layer had 60 neurons, the first hidden layer had 128 neurons, the second hidden layer had 64 neurons plus a 10% dropout. The third hidden layer still had 25 densely connected neurons, and the output layer just had one neuron. Using multiples of 32 had better results, multiples of 32  at that point but with another layer with dropout to ensure that the model wasn’t overfitting. \
\
My third and most successful model had an input layer of 60, the first hidden layer had 1024 neurons, the second hidden layer had 512 neurons with a 30% dropout rate, the third hidden layer had 256 densely connected neurons with a 20% dropout rate, the fourth hidden layer had 128 densely connected neurons and an output layer with 1 neuron. Comparisons were made of the three models with an RMSE score and calculations of the predicted movement direction (i.e. the change in close price percentage from the previous day increased or decreased). The RMSE loss function was used because RMSE gives a higher weight to large errors. High errors are very undesirable when predicting the stock market because if your model makes a large error, you could lose most of your money.
